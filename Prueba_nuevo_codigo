import numpy as np
import cv2
import threading as thr
import logging
from go1pylib import Go1, Go1Mode
import time
import paho.mqtt.client as mqtt

# Variables globales
x, y = None, None

def ajuste_color(frame, blue_decrease=23, blue_boost=30):
    b, g, r = cv2.split(frame)
    b = cv2.subtract(b, np.full(b.shape, blue_decrease, dtype=np.uint8))
    b = cv2.add(b, np.full(b.shape, blue_boost, dtype=np.uint8))
    return cv2.merge((b, g, r))

def add_uv_effect(frame, purple_boost=55, brightness_increase=37):
    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv_frame)
    s = cv2.add(s, np.full(s.shape, purple_boost, dtype=np.uint8))
    v = cv2.add(v, np.full(v.shape, brightness_increase, dtype=np.uint8))
    modified_hsv = cv2.merge((h, s, v))
    return cv2.cvtColor(modified_hsv, cv2.COLOR_HSV2BGR)

def follow_color(frame):
    GREEN_LOW = np.array([40, 100, 100], np.uint8)
    GREEN_HIGH = np.array([100, 255, 255], np.uint8)

    # Convierte el frame a espacio de color HSV
    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Crea una máscara para el color verde dentro del rango especificado
    mask_green = cv2.inRange(frame_hsv, GREEN_LOW, GREEN_HIGH)

    # Aplica la máscara para aislar el color verde en el frame original
    contours, _ = cv2.findContours(mask_green, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    x_center, y_center = None, None

    for contour in contours:
        area = cv2.contourArea(contour)
        if area < 500:
            continue
        M = cv2.moments(contour)
        if M["m00"] != 0:
            x_center = int(M["m10"] / M["m00"])
            y_center = int(M["m01"] / M["m00"])
            cv2.circle(frame, (x_center, y_center), 7, (0, 255, 0), -1)
            cv2.putText(frame, f"({x_center}, {y_center})", (x_center + 10, y_center - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    print(f"Coordenadas detectadas: x={x_center}, y={y_center}")
    return x_center, y_center

def process_video():
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("Error: No se pudo abrir la cámara.")
        return

    def process_frame():
        global x, y
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame = ajuste_color(frame)
            frame = add_uv_effect(frame)
            x, y = follow_color(frame)  # Actualizamos las coordenadas globales

            cv2.imshow("Video Procesado", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    # Hilo para procesamiento de video
    processing_thread = thr.Thread(target=process_frame, daemon=True)
    processing_thread.start()

    # Este hilo no se bloquea (no usamos join())
    cap.release()
    cv2.destroyAllWindows()

# Inicialización del robot
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def connect_to_robot():
    robot = Go1()
    robot.init()  # Conectar al robot
    return robot

mqtt_broker = "mqtt.eclipse.org"
mqtt_port = 1883

def on_connect(client, userdata, flags, rc):
    logger.info(f"Conectado a MQTT Broker con código {rc}")
    client.subscribe("robot/control")

def on_message(client, userdata, msg):
    logger.info(f"Mensaje recibido: {msg.payload.decode()}")

def mqtt_connect():
    client = mqtt.Client()
    client.on_connect = on_connect
    client.on_message = on_message
    try:
        client.connect(mqtt_broker, mqtt_port, 60)
        logger.info("Conexión MQTT exitosa.")
        client.loop_start()
    except Exception as e:
        logger.error(f"Error al conectar con MQTT: {e}")

def main():
    robot = connect_to_robot()
    mqtt_connect()

    # Mostrar nivel de batería
    battery_level = robot.get_battery_level()
    print(f"Nivel de batería: {battery_level}%")

    robot.set_mode(Go1Mode.STAND_DOWN)
    time.sleep(1)

    # Posiciones límites
    X1 = 270
    X2 = 280
    Y1 = 460
    Y2 = 465

    # Control del robot
    while True:
        global x, y
        if x is None or y is None:
            print("Encontrando punto verde")
        else:
            if X1 <= x <= X2:
                print("Rotar derecha")
            elif x > X2:
                print("Rotar izquierda")
            if 271 <= x <= X2:
                print("Adelante")
                if Y1 <= y <= Y2:
                    print("Llego")
                    break
        time.sleep(0.5)

# Ejecutar en segundo plano el procesamiento de video
process_video()

# Ejecutar el control del robot
main()
